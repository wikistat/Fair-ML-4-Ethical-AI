{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"height:80px; display: inline\"  alt=\"INSA\"/></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R Tutorial: Detect, Measure, Explain, Mitigate, Indirect Discrimination in Statistical Learning Algorithms\n",
    "\n",
    "**Short version**\n",
    "\n",
    "**Abstract**\n",
    "Analysis of data extracted from a 1994 US census and available on the [UCI repository](http://archive.ics.uci.edu/ml/). They allow us to relate the level of income (below or above 50k$), analogous to a \"solvency\" or credit score, with other variables, some of which are sensitive because they indicate membership in a group protected by law: gender, ethnic origin. Different indicators of bias, therefore sources of indirect discrimination against a group, are defined and illustrated on these data. The main ones, agreed in the literature, are the disproportionate effect or *disparate / adverse impact* (DI) (*demographic equality*), the conditional error rate (*overall error equality*) and measures associated with the asymmetry of the confusion matrices conditional on the group (*equalized odds*). The tutorial leads to estimate these different biases when predicting creditworthiness by logistic regression (linear), bianire tree and then a random forest algorithm. The \"official\" doctrine of *testing* surveys, adapted to detect direct individual discrimination, is also evaluated on the predictions of these two algorithms. Finally, an elementary procedure of systemic bias mitigation by *post-processing* is performed in order to evaluate its impact on the prediction accuracy and other biases. The objective, in order to meet the expectations of the future [European regulation](https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-european-approach-artificial-intelligence) on AI (*AI Act*) is to search, in an explicit and documented way for this AI system, for the least bad trade-off between prediction accuracy, explainability of a decision and control of discriminatory biases.\n",
    "\n",
    "**Notes**\n",
    "- The main results of this tutorial were used as an illustration for a presentation at a joint CNIL & Human rights advocate seminar (05/2020); they are explained in a submitted article ([Besse, 2020](https://hal.archives-ouvertes.fr/hal-02616963)) with respect to the obligations listed in the various articles of the *AI Act*.\n",
    "- This tutorial can be run locally after loading or cloning the repository or in the *Google Colab* cloud by clicking on the link below:\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/wikistat/Fair-ML-4-Ethical-AI/blob/master/AdultCensus/AdultCensus-R-biasDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "### The data\n",
    "Public data available on the [UCI repository] site (http://archive.ics.uci.edu/ml/) are extracted from the database of the 1994 US census. The two files *train* and *test* have been combined into one. These data are widely used and are a reference as a *benchmark* tool to compare the performances of learning methods. The objective is to predict, with more or less bias, the binary variable \"annual income\" greater or less than 50k$. This prediction does not impact the person but as the approach and the context are quite similar to what a bank could do to evaluate a credit risk, this example is very illustrative. This dataset is systematically used (sandbox) to evaluate the properties of fair learning algorithms because, contrary to many other datasets used for this purpose (*e.g. german credit bank*), the true value of the target variable is known as well as the ethnicity of the persons concerned.\n",
    "\n",
    "In the initial data, 48,842 individuals are described by the 14 variables in the table below :\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "|Num|Libellé|Ensemble de valeurs|\n",
    "|-|---------:|-------------------:|\n",
    "|1|`Age`|real|\n",
    "|2|`workClass`|Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked|\n",
    "|3|`fnlwgt`|real|\n",
    "|4|`education`|Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool|\n",
    "|5|`educNum`|integer|\n",
    "|6|`mariStat`|Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse|\n",
    "|7|`occup`|Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces|\n",
    "|8|`relationship`|Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\n",
    "|9|`origEthn`|White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black|\n",
    "|10|`sex`|Female, Male|\n",
    "|11|`capitalGain`|real| \n",
    "|12|`capitalLoss`|real|\n",
    "|13|`hoursWeek`|real|\n",
    "|14|`nativCountry`|United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands|\n",
    "|15|`income`|>50K, <=50K|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "The processing starts with a detailed preparation of the data:\n",
    "- reading and taking over the data, noticing that the variable `fnlwgt` (Final sampling weight) has a [special status](http://web.cs.wpi.edu/~cs4341/C00/Projects/fnlwgt) that is not very clear; it is eliminated;\n",
    "- deletion of observations with missing data, errors or inconsistencies,\n",
    "- grouping of highly scattered modalities, \n",
    "- removal of redundant variables. \n",
    "\n",
    "### Estimating bias\n",
    "\n",
    "Of all the existing criteria for bias that might point to indirect discrimination (Zliobaitė, 2015), three were favored (see Vermat and Rubin, 2018): \n",
    "1. indirect discrimination through disproportionate impact: *disparate impact* or *demographic equality*\n",
    "2. conditional error rate comparison: *overall error equality*\n",
    "3. comparison of odds ratios: *conditional procedure accuracy equality* or *disparate mistreatment* or *equalized odds*.\n",
    "\n",
    "\n",
    "The emphasis in this first tutorial is on estimating the *disparate impact* or *adverse impact* of gender. The confidence interval approximation (Besse et al. 2021) is compared with a *bootstrap* estimate leading to the same results. Estimates are computed on the initial database  (societal or systemic bias) and then on the income predictions obtained by two algorithms (logistic regression and random forests) to assess the risk of discrimination. The impact of post-processing attenuation of this bias is evaluated on the accuracy and other types of bias.\n",
    "\n",
    "**Notes** \n",
    "- a [more detailed](https://github.com/wikistat/Fair-ML-4-Ethical-AI/blob/master/AdultCensus/AdultCensus-R-biasDetectionLong.ipynb) but longer notebook proposes a comparison of the impacts of the other learning algorithms and thus of their discriminatory effect as a function of the society bias (gender and ethnic origin). This allows us to better understand the importance of taking into account the interactions between the variables. \n",
    "- The site [aif360](https://aif360.mybluemix.net/) also proposes a set of examples and tutorials. It is richer: other datasets, other criteria and especially more debiasing algorithms, but presents either trivial demonstrations or examples of very sophisticated methods of bias mitigation. This tutorial is more pedagogical to understand step by step the problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "In this phase of the work, there are two radically different views. \n",
    "- The one illustrated by Friedler et al. (2019) consists in training an algorithm on the raw data without prior \"human\" exploration using statistical skills; as a matter of principle, everything is automated.\n",
    "- The one proposed in this tutorial is the result of an approach requiring elementary statistical skills to explore the data, understand their structure, detect potential problems: missing data, atypical data, biases, rare classes, \"abnormal\" distributions...) in order to remedy them as best as possible, and to illustrate the interest of the objective pursued. \n",
    "\n",
    "Note that this second point of view of data knowledge is more respectful of the [EC expert guidelines for trustworthy AI](https://ec.europa.eu/futurium/en/ai-alliance-consultation) and anticipates the proposed [European regulation](https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-european-approach-artificial-intelligence) (*AI Act*) which imposes the drafting of explicit documentation (Annex IV) on prior studies of data quality and relevance.\n",
    "\n",
    "### Reading and first transformations\n",
    "Two possibilities to load the data from the UCI repository depending on the execution mode adopted; locally after installing R or remotely in the *Google Colab* cloud. \n",
    "1. In the first case, the data is loaded at the same time as the *Github* repository,\n",
    "2. In the second case, <a href=\"https://colab.research.google.com/github/wikistat/Fair-ML-4-Ethical-AI/blob/master/AdultCensus/AdultCensus-R-biasDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "the data and the transformation program are loaded and read in the *Google Colab* environment; it is necessary to run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell when running in the Google Colab cloud\n",
    "# otherwise data and functions are already loaded locally\n",
    "system(\"wget -P . https://github.com/wikistat/Fair-ML-4-Ethical-AI/raw/master/AdultCensus/adultTrainTest.csv\")\n",
    "system(\"wget -P . https://github.com/wikistat/Fair-ML-4-Ethical-AI/raw/master/AdultCensus/dataPrepAdultCensus.R\")\n",
    "system(\"mkdir ../Functions\")\n",
    "system(\"wget -P ../Functions https://raw.githubusercontent.com/wikistat/Fair-ML-4-Ethical-AI/master/Functions/dispImp.R\")\n",
    "system(\"wget -P ../Functions https://raw.githubusercontent.com/wikistat/Fair-ML-4-Ethical-AI/master/Functions/overErrEqual.R\")\n",
    "system(\"wget -P ../Functions https://raw.githubusercontent.com/wikistat/Fair-ML-4-Ethical-AI/master/Functions/oddsEqual.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the data preparation program, review the code to study its main features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:18.067284Z",
     "start_time": "2020-03-22T10:28:16.515Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source(\"dataPrepAdultCensus.R\")\n",
    "dataBase = dataPrepAdultCensus()\n",
    "summary(dataBase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic statistical description\n",
    "To highlight difficulties present on certain variables or pairs of variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:18.279443Z",
     "start_time": "2020-03-22T10:28:16.594Z"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=4, repr.plot.height=4)\n",
    "hist(dataBase[,\"LcapitalGain\"],probability=T, main=\"\",xlab=\"log(1+CapitalGain)\")\n",
    "boxplot(dataBase[,\"LcapitalGain\"], horizontal=TRUE,boxwex=.2,  outline=TRUE,  \n",
    "        frame=F, col = \"lightgrey\", add = TRUE,at=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asymmetric distribution, hence the need to transform certain variables before building linear models, and then highlighting inconsistencies and strong redundancies between certain variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:18.300927Z",
     "start_time": "2020-03-22T10:28:16.669Z"
    }
   },
   "outputs": [],
   "source": [
    "table(dataBase$relationship,dataBase$sex)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:18.327745Z",
     "start_time": "2020-03-22T10:28:16.676Z"
    }
   },
   "outputs": [],
   "source": [
    "table(dataBase$education,dataBase$educNum)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:18.357021Z",
     "start_time": "2020-03-22T10:28:16.681Z"
    }
   },
   "outputs": [],
   "source": [
    "table(dataBase$mariStat,dataBase$relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:18.382033Z",
     "start_time": "2020-03-22T10:28:16.686Z"
    }
   },
   "outputs": [],
   "source": [
    "table(dataBase$origEthn,dataBase$nativCountry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:18.448324Z",
     "start_time": "2020-03-22T10:28:16.690Z"
    }
   },
   "outputs": [],
   "source": [
    "mosaicplot(table(dataBase[,\"origEthn\"],dataBase[,\"income\"]),main=\"\", col=\"lightblue\",cex=1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some modifications are made in the database; variables are deleted in order to keep only one presence of sensitive information: gender and ethnic origin.\n",
    "- Deletion of variable 3 `fnlwgt` which has little meaning for this analysis.\n",
    "- Creation of a binary variable `Child`: presence or not of children.\n",
    "- Removal of variable 8 `relationship` which is redundant with gender and marital status,\n",
    "- Removal of variable 14 `nativCountry` redundant with ethnic origin.\n",
    "- The variable 9 `originEthn` is simplified to 2 classes: CaucYes *vs.* CaucNo\n",
    "\n",
    "**Note** For the following, it is important that the levels of the factors are ordered in a coherent way for the correct interpretation of the contingency tables and their numbers. By convention, the pre-judged socially \"unfavorable\" modalities: low income, female, non-Caucasian (coded 0), precede the others: high income, male, Caucasian (coded 1). It is therefore necessary either to reorder the levels of the `income' variable or to rename the modalities to match the alphabetical order; this second choice is carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:18.530959Z",
     "start_time": "2020-03-22T10:28:16.765Z"
    }
   },
   "outputs": [],
   "source": [
    "dataBase[,\"child\"]=as.factor(ifelse(dataBase$relationship=='Own-child',\"ChildYes\",\"ChildNo\"))\n",
    "dataBase[,\"origEthn\"]=as.factor(ifelse(dataBase$origEthn %in% c('Amer-Indian','Asian','Black','Other'),\"CaucNo\",\"CaucYes\"))\n",
    "dataBase[,\"income\"]=as.factor(ifelse(dataBase$income=='incLow',\"incB\",\"incH\"))\n",
    "datBas=dataBase[,-c(3,8,14)]\n",
    "summary(datBas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic *mosaicplots* show the relationship of the sensitive variables to the target (income threshold) and clearly highlight the social bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:18.567645Z",
     "start_time": "2020-03-22T10:28:16.829Z"
    }
   },
   "outputs": [],
   "source": [
    "mosaicplot(table(datBas[,\"sex\"],datBas[,\"income\"]),main=\"\", col=\"lightblue\",cex=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:18.610285Z",
     "start_time": "2020-03-22T10:28:16.833Z"
    }
   },
   "outputs": [],
   "source": [
    "mosaicplot(table(datBas[,\"origEthn\"],datBas[,\"income\"]),main=\"\",col=\"lightblue\",cex=1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comments on the biases present in the database, the imbalances of the classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample preparation\n",
    "The database is divided into two samples: training and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:18.652442Z",
     "start_time": "2020-03-22T10:28:16.960Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(datBas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection of the variables used in the following, the qualitative variables obtained from the quantitative ones are not included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:18.878493Z",
     "start_time": "2020-03-22T10:28:16.964Z"
    }
   },
   "outputs": [],
   "source": [
    "datBas=datBas[,c(\"age\",\"educNum\",\"mariStat\",\"occup\",\"origEthn\",\n",
    "                 \"sex\",\"hoursWeek\",\"income\",\"LcapitalGain\",\"LcapitalLoss\",\"child\")]\n",
    "summary(datBas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of learning, validation and test samples. You can change the initial `seed` value of the random number generator to obtain a different split between learning, validation and testing.\n",
    "\n",
    "Since the initial sample is relatively large, and in accordance with the expectations of the *AI Act* project, a validation sample is used for hyper-parameter optimization instead of the more accurate but cumbersome cross-validation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:18.905176Z",
     "start_time": "2020-03-22T10:28:16.967Z"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(11) # initialize the generator\n",
    "# extraction of samples\n",
    "test.ratio=.2 # proportion of test sample\n",
    "npop=nrow(datBas) # number of rows in the data\n",
    "nvar=ncol(datBas) # number of columns\n",
    "# size of validation and test samples\n",
    "ntest=ceiling(npop*test.ratio) \n",
    "# indices of the test sample\n",
    "testi=sample(1:npop,ntest)\n",
    "# remaining indices of the sample\n",
    "resti=setdiff(1:npop,testi); nrest=length(resti)\n",
    "# indices of the validation sample\n",
    "vali=resti[sample(1:nrest,ntest)]\n",
    "# indices of the learning sample\n",
    "appri=setdiff(resti,vali)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:19.155030Z",
     "start_time": "2020-03-22T10:28:16.972Z"
    }
   },
   "outputs": [],
   "source": [
    "# construction of the learning sample\n",
    "datApp=datBas[appri,]\n",
    "# construction of the test sample \n",
    "daTest=datBas[testi,]\n",
    "# construction of the validation sample\n",
    "datVal=datBas[vali,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of a function to calculate the usual error rate of the confusion matrix. With modality ordering, the well-ordered are the diagonal terms of the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:19.172350Z",
     "start_time": "2020-03-22T10:28:17.039Z"
    }
   },
   "outputs": [],
   "source": [
    "tauxErr=function(table){round((table[1,2]+table[2,1])/sum(table)*100,2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different results are stored in a table for the purpose of a comparative synthesis graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matRes=data.frame(matrix(0,8,4))\n",
    "rownames(matRes)=c(\"dataBaseBias\",\"linLogit\",\"tree\",\"linLogit_w_S\",\"testingLogit\",\"randomForest\",\"TreeDiscrPos\",\"RFdiscrPos\")\n",
    "colnames(matRes)=c(\"Lower\",\"DI\",\"Upper\",\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income prediction\n",
    "A detailed comparison (cf. the [tutorial](https://github.com/wikistat/Apprentissage/blob/master/Adult-Census/Apprent-Python-AdultCensus.ipynb)) of most of the models and algorithms for predicting the income as a function of the different variables shows slightly better prediction results obtained by the *gradient boosting* algorithm (extrem version). Nevertheless, we can limit ourselves here to a more restricted choice of models and algorithms to understand the impact on the discrimination between:\n",
    "- interpretable (linear) logistic regression,\n",
    "- a binary decision tree,\n",
    "- random forests (non-linear integrating interactions) but without interpretation capacity.\n",
    "\n",
    "A binary tree leads to intermediate forecasting qualities between logistic regression and random forest but is not easily interpretable because of the \"optimal\" but high number of leaves.\n",
    "\n",
    "### Forecasting by [logistic regression](http://wikistat.fr/pdf/st-m-app-rlogit.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:21.296744Z",
     "start_time": "2020-03-22T10:28:17.107Z"
    }
   },
   "outputs": [],
   "source": [
    "# estimation of the complete model\n",
    "log.lm=glm(income~.,data=datApp,family=binomial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:21.327316Z",
     "start_time": "2020-03-22T10:28:17.177Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(log.lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Q** Interpreting the role of variables on the income threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:21.369423Z",
     "start_time": "2020-03-22T10:28:17.243Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction of the test sample\n",
    "pred.log=predict(log.lm,newdata=daTest,type=\"response\")\n",
    "# Confusion matrix for the prediction of \n",
    "# Threshold overflow\n",
    "confMat=table(pred.log>0.5,daTest$income)\n",
    "confMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:21.388437Z",
     "start_time": "2020-03-22T10:28:17.247Z"
    }
   },
   "outputs": [],
   "source": [
    "err=tauxErr(confMat)\n",
    "matRes[2,4]=(100-err)/100\n",
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** A logistic regression model with interactions, i.e. quadratic, does not lead to a significantly better prediction but requires a variable selection (*e.g. stepwise* or `both`) that is time consuming. For the sake of brevity, it is not reproduced; see the [more complete notebook](https://github.com/wikistat/Fair-ML-4-Ethical-AI/blob/master/AdultCensus/AdultCensus-R-biasDetectionLong.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary tree forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:21.424738Z",
     "start_time": "2020-03-22T10:28:17.383Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(datApp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: uncomment the installation command below when running in the cloud or if this library is simply not installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"rpart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rpart)\n",
    "# Estimation of complete model\n",
    "tree.mod=rpart(income~.,data=datApp,cp=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation of the penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmat=xpred.rpart(tree.mod)\n",
    "xerr=(xmat-as.integer(datApp[,\"income\"]))^2\n",
    "CVerr=apply(xerr,2,sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as.numeric(attributes(which.min(CVerr))$names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.opt=rpart(income~.,data=datApp,control=rpart.control(cp=as.numeric(attributes(which.min(CVerr))$names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(partykit)\n",
    "options(repr.plot.width=16, repr.plot.height=16)\n",
    "plot(as.party(tree.opt), type=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What about the clarity of interpretation of this model?\n",
    "\n",
    "**Q** What about the presence of the gender variable?\n",
    "\n",
    "Estimate of the error on the test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.tree=predict(tree.opt,newdata=daTest,type=\"class\")\n",
    "confMat=table(pred.tree,daTest$income)\n",
    "confMat\n",
    "err=tauxErr(confMat)\n",
    "matRes[3,4]=(100-err)/100\n",
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simpler model is obtained by increasing the penalty but with the consequence of restricting the performances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.int=rpart(income~.,data=datApp,control=rpart.control(cp=0.005))\n",
    "plot(as.party(tree.int), type=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.tree=predict(tree.int,newdata=daTest,type=\"class\")\n",
    "confMat=table(pred.tree,daTest$income)\n",
    "confMat\n",
    "tauxErr(confMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting by [random forests](http://wikistat.fr/pdf/st-m-app-agreg.pdf)\n",
    "\n",
    "**Q** What are the default options used below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:21.456485Z",
     "start_time": "2020-03-22T10:28:17.386Z"
    }
   },
   "outputs": [],
   "source": [
    "# install.packages(\"randomForest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:45.310732Z",
     "start_time": "2020-03-22T10:28:17.391Z"
    }
   },
   "outputs": [],
   "source": [
    "library(randomForest)\n",
    "rf.mod=randomForest(income~.,data=datApp)\n",
    "pred.rf=predict(rf.mod,newdata=daTest,type=\"response\")\n",
    "confMat=table(pred.rf,daTest$income)\n",
    "confMat\n",
    "err=tauxErr(confMat)\n",
    "matRes[6,4]=(100-err)/100\n",
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Compare the results obtained, accuracy and explainability.\n",
    "\n",
    "The calculations can also be carried out by considering ethnic origin as a sensitive variable (see the [more complete notebook](https://github.com/wikistat/Fair-ML-4-Ethical-AI/blob/master/AdultCensus/AdultCensus-R-biasDetectionLong.ipynb)) but the results are less clear-cut, less \"pedagogical\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model without the gender variable\n",
    "A very naive approach to build a \"fair\" learning consists in removing the sensitive variable. The logistic regression model is then estimated without this variable in order to evaluate the impact on the bias later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:45.691895Z",
     "start_time": "2020-03-22T10:28:17.460Z"
    }
   },
   "outputs": [],
   "source": [
    "# estimation  of the model \n",
    "log_g.lm=glm(income~.,data=datApp[,-6],family=binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:45.722613Z",
     "start_time": "2020-03-22T10:28:17.463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred_g.log=predict(log_g.lm,newdata=daTest[,-8],type=\"response\")\n",
    "# Confusion matrix  \n",
    "confMat=table(pred_g.log>0.5,daTest$income)\n",
    "confMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:45.739468Z",
     "start_time": "2020-03-22T10:28:17.468Z"
    }
   },
   "outputs": [],
   "source": [
    "err=tauxErr(confMat)\n",
    "matRes[4,4]=(100-err)/100\n",
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What about the prediction accuracy without the gender variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Estimating Disparate Impact\n",
    "### Definition\n",
    "Indirect or group discrimination measures are based on a *disparate  impact* (*DI*) criterion that appeared in the US in 1971 (Barocas and Selbst, 2016) to detect discrimination in hiring. This criterion is defined by the ratio of two probabilities: the probability of benefiting from a favorable situation or decision (high income, credit, job, housing...) for a person from the group protected by the law (woman or non-Caucasian origin), over the same probability for a person from the other group (man or Caucasian origin).\n",
    "\n",
    "*Notations*: \n",
    "\n",
    "- $Y$ is the target or explainable variable, here income, $Y=1$ high income *vs* $Y=0$; \n",
    "- $g(X)=\\hat{Y}$ the high or low score or income prediction, $g(X)=\\hat{Y}=0$: low income prediction;\n",
    "- $S$ is the sensitive variable that designates the group that is in principle protected by law from possible discrimination. This is male ($S=1$) or female ($S=0$). \n",
    "\n",
    "The disproportionate effect measures a situation of societal bias already present in the database. \n",
    "$$DI=\\frac{P(Y=1|S=0)}{P(Y=1|S=1)}.$$\n",
    "It is estimated from the values of the contingency table crossing the variables $Y$ and $S$ by the ratio:\n",
    "$$\\frac{n_{21}}{(n_{11}+n_{21})}/\\frac{n_{22}}{(n_{12}+n_{22})}.$$\n",
    "\n",
    "Applied to the forecast $g(X)=\\hat{Y}$ of the target variable $Y$, it measures the bias of this forecast and thus the discrimination risk operated by the prediction.\n",
    "\n",
    "### `dispImp` function\n",
    "A R function computes the $DI$ and additionally provides a confidence interval estimate [Besse et al, 2020](https://arxiv.org/pdf/2003.14263.pdf)\n",
    " decomposing the density function of the test statistic by the *delta method*. This function has three arguments:   \n",
    "- the variable $S$ considered sensitive: a two-level ordered factor \"unfavorable\" and then \"favorable\";\n",
    "- the target variable $Y$ or its prediction $g(X)=\\hat{Y}$: also a factor at two levels unfavorable then favorable;\n",
    "- the risk of the confidence interval, by default 5%.\n",
    "\n",
    "This function returns the three estimates $DI$ and $IC_g$, $IC_d$ bounds of the confidence interval.\n",
    "\n",
    "Morris S., Lobsenz R. (2000) had already suggested to compute an estimate of the *DI* by confidence interval but by making the hypothesis of Gaussian distributions; this approximation is not justified for the numbers in a contingency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:45.760439Z",
     "start_time": "2020-03-22T10:28:17.604Z"
    }
   },
   "outputs": [],
   "source": [
    "source(\"../Functions/dispImp.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disproportionate effect or bias in the learning base \n",
    "\n",
    "The function `dispImp` requires that the levels of the factors are in lexicographic order: levels \"unfavorable\" then \"favorable\".\n",
    "\n",
    "Contingency table crossing $Y$ (income) with $S$ (gender)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:45.780646Z",
     "start_time": "2020-03-22T10:28:17.674Z"
    }
   },
   "outputs": [],
   "source": [
    "tableDI=table(datBas$income,datBas$sex)\n",
    "tableDI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pointwise estimate* of $DI=\\frac{n_{21}}{(n_{11}+n_{21})}/\\frac{n_{22}}{(n_{12}+n_{22})}.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:45.803362Z",
     "start_time": "2020-03-22T10:28:17.735Z"
    }
   },
   "outputs": [],
   "source": [
    "round((tableDI[2,1]/(tableDI[1,1]+tableDI[2,1]))/(tableDI[2,2]/(tableDI[1,2]+tableDI[2,2])),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Confidence interval estimation* approximated by *delta method*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:45.860878Z",
     "start_time": "2020-03-22T10:28:17.797Z"
    }
   },
   "outputs": [],
   "source": [
    "round(dispImp(datBas[,\"sex\"],datBas[,\"income\"]),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment on the bias measured by this way, compare with the graph obtained (*mosaic plot*) during the exploration.\n",
    "\n",
    "*[Bootstrap estimate](http://wikistat.fr/pdf/st-m-app-bootstrap.pdf) of the confidence interval*\n",
    "\n",
    "The estimate of the confidence interval is compared with the behavior of the *DI* on *bootstrap* samples (Efron 1987)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:47.552814Z",
     "start_time": "2020-03-22T10:28:17.862Z"
    }
   },
   "outputs": [],
   "source": [
    "B=1000 \n",
    "set.seed(11)\n",
    "n=nrow(datBas)\n",
    "res=matrix(0,B,1)\n",
    "for (i in 1:B)\n",
    "    {\n",
    "    boot=sample(n,n,replace=T)\n",
    "    res[i,]=dispImp(datBas[boot,\"sex\"],datBas[boot,\"income\"])[2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:47.666234Z",
     "start_time": "2020-03-22T10:28:17.866Z"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=15, repr.plot.height=8)\n",
    "DI_confInt_delta <- round(dispImp(datBas[,\"sex\"], datBas[,\"income\"]), 3)\n",
    "plot(res,ylim=range(res),pch='.')\n",
    "lines(res,col=3,pch='.')\n",
    "abline(h=DI_confInt_delta[c(1, 3)], col=2) \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What about the *DI* estimates on bootstrap samples compared to the bounds of the confidence interval?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function of the `boot` library provides a bootstrap estimate of the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:27.828668Z",
     "start_time": "2020-03-22T10:28:17.936Z"
    }
   },
   "outputs": [],
   "source": [
    "library(boot)\n",
    "fc <- function(d, i){ \n",
    "    d2 <- d[i,]\n",
    "    return(statistic=dispImp(d2$sex,d2$income)[2])\n",
    "}\n",
    "set.seed(11)\n",
    "bootDI <- boot(datBas,fc, R=1000)\n",
    "bootDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:27.863623Z",
     "start_time": "2020-03-22T10:28:17.940Z"
    }
   },
   "outputs": [],
   "source": [
    "boot.ci(boot.out = bootDI, type = \"perc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Compare the delta method approximation and the bootstrap estimation of the confidence interval.\n",
    "\n",
    "**Q** Given the computation time, which one should be preferred?\n",
    "\n",
    "The interval is finally estimated on the test sample in order to compare with these different predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic=round(dispImp(daTest[,\"sex\"],daTest[,\"income\"]),3)\n",
    "matRes[1,]=c(ic, 1)\n",
    "ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What about the size of the confidence interval?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disparate impact of prediction \n",
    "\n",
    "The same ratio or disparate impact calculated on $g(X)$ forecasts of $Y$ rather than on $Y$ explicitly measures the effect of the forecast. It amounts to a test of the equality of favorable forecast rates between the two groups. \n",
    "\n",
    "The threshold value of the probability of predicting the level of income is set by default at $0.5$.\n",
    "\n",
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:27.879555Z",
     "start_time": "2020-03-22T10:28:18.095Z"
    }
   },
   "outputs": [],
   "source": [
    "Yhat=as.factor(pred.log>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:27.896673Z",
     "start_time": "2020-03-22T10:28:18.101Z"
    }
   },
   "outputs": [],
   "source": [
    "ic=round(dispImp(daTest[,\"sex\"],Yhat),3)\n",
    "matRes[2,1:3]=ic\n",
    "ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic=round(dispImp(daTest[,\"sex\"],pred.tree),3)\n",
    "matRes[3,1:3]=ic\n",
    "ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Random Forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:27.926111Z",
     "start_time": "2020-03-22T10:28:18.174Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ic=round(dispImp(daTest[,\"sex\"],pred.rf),3)\n",
    "matRes[6,1:3]=ic\n",
    "ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Compare the three confidence intervals of the *DI* estimate for the original data, the logistic regression forecast and the random forest forecast. Conclusion?\n",
    "\n",
    "#### Disparate impact of predictions without the sensitive variable gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:27.948769Z",
     "start_time": "2020-03-22T10:28:18.337Z"
    }
   },
   "outputs": [],
   "source": [
    "Yhat_g=as.factor(pred_g.log>0.5)\n",
    "ic=round(dispImp(daTest[,\"sex\"],Yhat_g),3)\n",
    "matRes[4,1:3]=ic\n",
    "ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What happens to the DI with a forecast that does not use the sensitive variable?\n",
    "\n",
    "The [long notebook](https://github.com/wikistat/Fair-ML-4-Ethical-AI/blob/master/AdultCensus/AdultCensus-R-biasDetectionLong.ipynb) verifies these results by considering (*Monte Carlo* cross-validation) 20 replications of the separation of the training and test samples on which three algorithms are trained: logistic regression, decision tree, *random forest*, before evaluating the observed DI on the test sample forecast. \n",
    "\n",
    "As expected, the accuracy depends strongly on the chosen algorithm. Moreover, we see here that the better the accuracy, the less the bias is reinforced compared to the `DIbase` of the training data. But, for a given algorithm, the *DI* is not correlated to the accuracy on a training sample.\n",
    "\n",
    "**Q** Partial conclusion on the impact of each algorithm, whose interpretability should also be taken into account, especially with respect to the American law.\n",
    "\n",
    "**Warning** as Friedler et al. (2019) remind us, results and conclusions can change from one dataset to another. This is already well known with respect to prediction accuracy, it is necessary to integrate it into the bias management. The results presented in this tutorial, are on some points, different from those of Friedler et al. (2019). The main reason for this is probably the difference in the strategy adopted for data preprocessing. As a matter of principle, Friedler et al. (2019) analyze without any elementary statistical perspective the raw data and thus without any prior processing. There may also be, to be verified, implementation differences between the R and Python versions of the algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disparate impact *vs. Testing*\n",
    "#### Survey commissioned by DARES\n",
    "*Testing* is originally a common method for detecting *direct* discrimination by a human. It has been \"adapted\" (Riach and Rich 2002) and deployed by the ([DARES](http://dares.travail-emploi.gouv.fr/dares-etudes-et-statistiques/etudes-et-syntheses/dares-analyses-dares-indicateurs-dares-resultats/testing)) of the Ministry of Labour (cf. [article Le Monde 2020](https://www.lemonde.fr/societe/article/2020/01/08/une-etude-montre-des-discriminations-a-l-embauche-significatives-en-fonction-de-l-origine_6025227_3224.html)) to detect indirect discrimination against a group by survey. It consists in evaluating the variability of a decision when only the modality of the sensitive variable is modified. \n",
    "\n",
    "The calculations below allow to reproduce the global results of the last DARES survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:27.993612Z",
     "start_time": "2020-03-22T10:28:18.519Z"
    }
   },
   "outputs": [],
   "source": [
    "origine.i=matrix(0,10000,1);reponse.i=matrix(0,10000,1)\n",
    "origine.i[4536:8910]=1;origine.i[9376:10000]=1\n",
    "reponse.i[8911:10000]=1\n",
    "origine=factor(origine.i,labels=c(\"Maghreb\",\"France\"))\n",
    "reponse=factor(reponse.i,labels=c(\"Negative\",\"Positive\"))\n",
    "table(reponse, origine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:28.027490Z",
     "start_time": "2020-03-22T10:28:18.524Z"
    }
   },
   "outputs": [],
   "source": [
    "100*465/5000;100*625/5000; 465/625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratios are indeed those of the survey. There are many, many ways to compare them in order to conclude whether or not a discirmination is considered significant. What does the disproportionate effect assessment look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:28.088088Z",
     "start_time": "2020-03-22T10:28:18.607Z"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=4, repr.plot.height=4)\n",
    "mosaicplot(table(origine,reponse),main=\"\",col=\"lightblue\",cex=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:28.124484Z",
     "start_time": "2020-03-22T10:28:18.613Z"
    }
   },
   "outputs": [],
   "source": [
    "round(dispImp(origine,reponse),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Does this *testing* survey show statistically significant discrimination under the U.S. regulations (4/5 rule)?\n",
    "\n",
    "**Q** What about the accuracy of the *DI* assessment with 10,000 resumes sent? Would it be possible to conclude for a given company?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Testing* of a learning algorithm\n",
    "\n",
    "What happens if *testing* is applied to an automatic decision driven by a learning algorithm? \n",
    "\n",
    "Income predictions are computed for the same people in the test sample, taking into account the initial gender and then the opposite gender. In this case, a woman for whom the income or creditworthiness prediction changes when the gender variable changes from `Female' to `Male' would be entitled to sue for direct discrimination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:28.161744Z",
     "start_time": "2020-03-22T10:28:18.769Z"
    }
   },
   "outputs": [],
   "source": [
    "daTest2=daTest\n",
    "# Gender change\n",
    "daTest2$sex=as.factor(ifelse(daTest$sex==\"Male\", \"Female\", \"Male\"))\n",
    "# Prediction of the \"new\" test sample\n",
    "pred2.log=predict(log.lm,daTest2,type=\"response\")\n",
    "Yhat2=as.factor(pred2.log>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:28.181824Z",
     "start_time": "2020-03-22T10:28:18.773Z"
    }
   },
   "outputs": [],
   "source": [
    "table(Yhat,Yhat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:28.221105Z",
     "start_time": "2020-03-22T10:28:18.776Z"
    }
   },
   "outputs": [],
   "source": [
    "# distribution by gender\n",
    "table(Yhat,Yhat2,daTest$sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Complete: There are $x+y$ people whose income expectation changes when they change gender. And the change is in the expected direction.\n",
    "- $x$ women go from a low income expectation to a high income expectation\n",
    "- $y$ men go the opposite way when they become women, so these men were positively discriminated against!\n",
    "\n",
    "What would be the results of a testing survey that sends the \"files\" to the algorithm twice, once for each gender? We must therefore consider twice as many people by concatenating the two forecasts. This leads to the contingency table below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:28.270819Z",
     "start_time": "2020-03-22T10:28:18.848Z"
    }
   },
   "outputs": [],
   "source": [
    "# concatenation function of two vectors of factor type\n",
    "c.factor <- function(..., recursive=TRUE) unlist(list(...), recursive=recursive) \n",
    "Yhat=factor(Yhat,labels=c(\"incB\",\"incH\")); Yhat2=factor(Yhat2,labels=c(\"incB\",\"incH\"))\n",
    "mosaicplot(table(c.factor(daTest$sex,daTest2[,\"sex\"]),c.factor(Yhat,Yhat2)),main=\"\",col=\"lightblue\",cex=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:28.288632Z",
     "start_time": "2020-03-22T10:28:18.852Z"
    }
   },
   "outputs": [],
   "source": [
    "ic=round(dispImp(c.factor(daTest$sex,daTest2[,\"sex\"]),c.factor(Yhat,Yhat2)),3)\n",
    "matRes[5,1:3]=ic\n",
    "ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T08:07:02.630240Z",
     "start_time": "2020-02-23T08:07:02.496Z"
    }
   },
   "source": [
    "**Q** Conclusion: is testing adequate to detect algorithmic discrimination?\n",
    "\n",
    "**Q** Think about the role of the gender variable in predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Testing* and \"unfair\" prediction \n",
    "A simple way for a company to protect itself against a *testing* operation consists in setting as predicted probability the maximum of the two probabilities obtained by exchanging the modalities of the sensitive variable. In general, choose the most favourable situation for the person whatever the observed gender. The individual discrimination detectable by *testing* is neutralized and the influence on the error rate is almost negligible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:28.327315Z",
     "start_time": "2020-03-22T10:28:19.012Z"
    }
   },
   "outputs": [],
   "source": [
    "fairPredictGenre=pmax(pred.log, pred2.log) \n",
    "confMat=table(fairPredictGenre>0.5,daTest$income)\n",
    "confMat;err=tauxErr(confMat)\n",
    "matRes[5,4]=(100-err)/100\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:28.356015Z",
     "start_time": "2020-03-22T10:28:19.015Z"
    }
   },
   "outputs": [],
   "source": [
    "round(dispImp(daTest$sex,as.factor(pred.log>0.5)),3)\n",
    "round(dispImp(daTest$sex,as.factor(fairPredictGenre>0.5)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning** This procedure masks **intentionally** direct discrimination detectable by testing while promoting indirect discrimination, it is clearly **condemnable under the penal code**. Be careful in your future professional practices!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain, mitigate discrimination?\n",
    "The logistic regression model notably reproduces the social bias and reinforces it by introducing discrimination; this is less clear for the random forest algorithm. Is it possible to explain this behavior or, more precisely, to use the right model or algorithm that avoids it? The [long notebook](https://github.com/wikistat/Fair-ML-4-Ethical-AI/blob/master/AdultCensus/AdultCensus-R-biasDetectionLong.ipynb) compares different algorithms in different situations, including unsuccessfully assigning more weight to women to compensate for their underrepresentation. \n",
    "\n",
    "The literature proposes an avalanche of methods for debiasing an algorithmic decision. Three approaches are developed:\n",
    "- *Pre-processing* by debiasing the training data;\n",
    "- *Processing* by penalizing the objective function with a fairness constraint but the optimization is no longer convex;\n",
    "- *Post-processing* by de-biasing the decisions.\n",
    "\n",
    "Friedler et al. (2019) and [AIF360](https://aif360.mybluemix.net/) provide a systematic numerical comparison of some of these approaches on several public datasets, including the one in this tutorial. \n",
    "\n",
    "A rudimentary but effective version of post-processing consists of estimating two models or training two algorithms, one for women and one for men and then adjusting the decision threshold to reduce the disproportionate effect while controlling the error rate. This procedure is tested in the cases of a binary tree and random forests. It is a way to introduce a dose of positive discrimination in order to move towards more social equity.\n",
    "\n",
    "The first part consists in estimating the models separately before introducing positive discrimination in a second part.\n",
    "\n",
    "**Note** It is probably not necessary to estimate two random forest models by gender. Post-processing the decision thresholds alone should be sufficient. \n",
    "\n",
    "### Separation of the two samples\n",
    "The samples are separated into two parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:28.411876Z",
     "start_time": "2020-03-22T10:28:19.197Z"
    }
   },
   "outputs": [],
   "source": [
    "datAppF=subset(datApp, sex == 'Female') \n",
    "datAppM=subset(datApp, sex == 'Male')\n",
    "datValF=subset(datVal, sex == 'Female') \n",
    "datValM=subset(datVal, sex == 'Male')\n",
    "daTestF=subset(daTest, sex == 'Female')\n",
    "daTestM=subset(daTest, sex == 'Male')\n",
    "summary(datAppM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "Estimation of the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:29.016959Z",
     "start_time": "2020-03-22T10:28:19.307Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg.log=glm(income~.,data=datApp,family=binomial)\n",
    "# estimation of  both models\n",
    "reg.logF=glm(income~.,data=datAppF[,-6],family=binomial)\n",
    "reg.logM=glm(income~.,data=datAppM[,-6],family=binomial)\n",
    "# comparison of parameters\n",
    "summary(reg.logF);summary(reg.logM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** La comparaison des paramètres des deux modèles apporte-t-elle des informations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:29.057811Z",
     "start_time": "2020-03-22T10:28:19.312Z"
    }
   },
   "outputs": [],
   "source": [
    "# predictions  of the models \n",
    "yHat=predict(reg.log,newdata=daTest,type=\"response\")\n",
    "yHatF=predict(reg.logF,newdata=daTestF,type=\"response\")\n",
    "yHatM=predict(reg.logM,newdata=daTestM,type=\"response\")\n",
    "# compilation of predictions\n",
    "yHatFM=c(yHatF,yHatM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:29.092408Z",
     "start_time": "2020-03-22T10:28:19.316Z"
    }
   },
   "outputs": [],
   "source": [
    "daTestFM=rbind(daTestF,daTestM)\n",
    "dim(daTestFM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:29.120234Z",
     "start_time": "2020-03-22T10:28:19.321Z"
    }
   },
   "outputs": [],
   "source": [
    "# errors\n",
    "table(yHatFM>0.5,daTestFM$income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:29.149172Z",
     "start_time": "2020-03-22T10:28:19.325Z"
    }
   },
   "outputs": [],
   "source": [
    "table(yHat>0.5,daTest$income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:29.178234Z",
     "start_time": "2020-03-22T10:28:19.330Z"
    }
   },
   "outputs": [],
   "source": [
    "tauxErr(table(yHatFM>0.5,daTestFM$income))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:29.198020Z",
     "start_time": "2020-03-22T10:28:19.335Z"
    }
   },
   "outputs": [],
   "source": [
    "tauxErr(table(yHat>0.5,daTest$income))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What happens to the prediction error once the two models are combined with the same decision threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:29.223712Z",
     "start_time": "2020-03-22T10:28:19.443Z"
    }
   },
   "outputs": [],
   "source": [
    "# cumulated bias  vs. bias\n",
    "round(dispImp(daTestFM[,\"sex\"],as.factor(yHatFM>0.5)),3); round(dispImp(daTest[,\"sex\"],as.factor(yHat>0.5)),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:29:29.252714Z",
     "start_time": "2020-03-22T10:28:19.448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reminder: Bias of the test base\n",
    "round(dispImp(daTestFM[,\"sex\"],daTestFM[,\"income\"]),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What happens to the bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary tree \n",
    "The objective is to search for a less bad compromise between accuracy, interpretability and bias. We limit ourselves to simple trees by introducing a sub-optimal penalty which imposes a limited number of leaves. This parameter deserves to be \"optimized\" but the objective function is not clear, depending on political and commercial imperatives in the search for a compromise. We retain the choice made previously on the validation sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rpart)\n",
    "# Initial model\n",
    "tree.init=tree.int=rpart(income~.,data=datApp,control=rpart.control(cp=0.005))\n",
    "# estimation of the two models\n",
    "tree.F=rpart(income~.,data=datAppF[,-6],control=rpart.control(cp=0.005))\n",
    "tree.M=rpart(income~.,data=datAppM[,-6],control=rpart.control(cp=0.005))\n",
    "# tree comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=10, repr.plot.height=10)\n",
    "plot(as.party(tree.F), type=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(as.party(tree.M), type=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model prediction\n",
    "yHatTree=predict(tree.init,newdata=daTest,type=\"class\")\n",
    "yHatFtree=predict(tree.F,newdata=daTestF,type=\"class\")\n",
    "yHatMtree=predict(tree.M,newdata=daTestM,type=\"class\")\n",
    "# compilation of the predictions\n",
    "yHatFMtree=c(yHatFtree,yHatMtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative error vs. initial RF error\n",
    "table(yHatFMtree,daTestFM$income); table(yHatTree,daTest$income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tauxErr(table(yHatFMtree,daTestFM$income))\n",
    "tauxErr(table(yHatTree,daTest$income))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative bias vs. initial model bias vs. base bias\n",
    "round(dispImp(daTestFM[,\"sex\"],as.factor(yHatFMtree)),3)\n",
    "round(dispImp(daTest[,\"sex\"],as.factor(yHatTree)),3)\n",
    "round(dispImp(daTestFM[,\"sex\"],daTestFM[,\"income\"]),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  *Random Forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:30:19.647142Z",
     "start_time": "2020-03-22T10:28:19.666Z"
    }
   },
   "outputs": [],
   "source": [
    "library(randomForest)\n",
    "# Initial model\n",
    "RFinit=randomForest(income~.,data=datApp)\n",
    "# Model by changing the weights\n",
    "RFinitW=randomForest(income~.,data=datApp,weigth=w)\n",
    "# estimation of the two models\n",
    "RF.F=randomForest(income~.,data=datAppF[,-6])\n",
    "RF.M=randomForest(income~.,data=datAppM[,-6])\n",
    "# comparison of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:30:21.439024Z",
     "start_time": "2020-03-22T10:28:19.672Z"
    }
   },
   "outputs": [],
   "source": [
    "# model prediction\n",
    "yHatrf=predict(RFinit,newdata=daTest,type=\"response\")\n",
    "yHatrfW=predict(RFinitW,newdata=daTest,type=\"response\")\n",
    "yHatFrf=predict(RF.F,newdata=daTestF,type=\"response\")\n",
    "yHatMrf=predict(RF.M,newdata=daTestM,type=\"response\")\n",
    "# compilation of forecasts\n",
    "yHatFMrf=c(yHatFrf,yHatMrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:30:21.472726Z",
     "start_time": "2020-03-22T10:28:19.676Z"
    }
   },
   "outputs": [],
   "source": [
    "# cumulative error vs. initial RF error\n",
    "table(yHatFMrf,daTestFM$income); table(yHatrf,daTest$income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Compare errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:30:21.498267Z",
     "start_time": "2020-03-22T10:28:19.680Z"
    }
   },
   "outputs": [],
   "source": [
    "tauxErr(table(yHatFMrf,daTestFM$income))\n",
    "tauxErr(table(yHatrf,daTest$income))\n",
    "tauxErr(table(yHatrfW,daTest$income))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:30:21.529040Z",
     "start_time": "2020-03-22T10:28:19.685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cumulative bias vs. initial model bias vs. base bias\n",
    "round(dispImp(daTestFM[,\"sex\"],as.factor(yHatFMrf)),3)\n",
    "round(dispImp(daTest[,\"sex\"],as.factor(yHatrf)),3)\n",
    "round(dispImp(daTest[,\"sex\"],as.factor(yHatrfW)),3)\n",
    "round(dispImp(daTestFM[,\"sex\"],daTestFM[,\"income\"]),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Compare biases \n",
    "\n",
    "### Discrimination mitigation by *post-processing*.\n",
    "The  (*post-processing*) procedure below is the simplest. It consists in introducing a form of positive discrimination by modifying the decision threshold for women while keeping the default one of $0.5$ for men in order not to penalize them more. It is applied in this tutorial to the tree and random forest algorithms only. A graphical optimization procedure has been applied but not reproduced in order to control, on the validation sample, the effect of the correction on both the bias and the prediction error. The threshold chosen ($0.3$) for women with random forests to decide on a high income ($>50$k$) follows. *Warning* this threshold may depend on the validation sample and therefore on the initialization of the random number generator. To illustrate the choice of the threshold, the ROC curves below are instructive.\n",
    "\n",
    "#### ROC curves plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ROCR)\n",
    "options(repr.plot.width=15, repr.plot.height=15)\n",
    "ROCtreeM=predict(tree.M,newdata=datValM,type=\"prob\")[,2]\n",
    "predTreeM=prediction(ROCtreeM,datValM$income)\n",
    "perfTreeM=performance(predTreeM,\"tpr\",\"fpr\")\n",
    "ROCtreeF=predict(tree.F,newdata=datValF,type=\"prob\")[,2]\n",
    "predTreeF=prediction(ROCtreeF,datValF$income)\n",
    "perfTreeF=performance(predTreeF,\"tpr\",\"fpr\")\n",
    "\n",
    "ROCrfM=predict(RF.M,newdata=datValM,type=\"prob\")[,2]\n",
    "predRfM=prediction(ROCrfM,datValM$income)\n",
    "perfRfM=performance(predRfM,\"tpr\",\"fpr\")\n",
    "ROCrfF=predict(RF.F,newdata=datValF,type=\"prob\")[,2]\n",
    "predRfF=prediction(ROCrfF,datValF$income)\n",
    "perfRfF=performance(predRfF,\"tpr\",\"fpr\")\n",
    "\n",
    "par(cex=1.8,lwd=2)\n",
    "plot(perfTreeM,col=1, print.cutoffs.at=c(0.5))\n",
    "plot(perfTreeF,col=2, print.cutoffs.at=c(0.1, 0.5),add=TRUE)\n",
    "plot(perfRfM,col=3, print.cutoffs.at=c(0.5),add=TRUE)\n",
    "plot(perfRfF,col=4, print.cutoffs.at=c(0.3,0.5),add=TRUE)\n",
    "legend(\"bottomright\",legend=c(\"arbreMasc\",\"arbreFem\",\"RFmasc\",\"RFfem\"),col=c(1:4),cex=1,lwd=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: to bring the estimated values on the validation sample closer to the false positive rates while reducing the systemic bias without penalizing the errors too much...\n",
    "\n",
    "**Q** Binary trees: Comment on the \"optimality\" of the choice of thresholds $0.1$ for women and $0.5$ for men in view of these ROC curves.\n",
    "\n",
    "**Q** Same thing for random forests: $0.3$ and $0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary trees with positive discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of the models by changing the threshold of the women\n",
    "yHatFtreeDP=predict(tree.F,newdata=daTestF,type=\"prob\")[,2]>0.1\n",
    "yHatMtreeDP=predict(tree.M,newdata=daTestM,type=\"prob\")[,2]>0.5\n",
    "# compilation of predictions\n",
    "yHatFMtreeDP=c(yHatFtreeDP,yHatMtreeDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(yHatFMtreeDP,daTestFM$income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err=tauxErr(table(yHatFMtreeDP,daTestFM$income))\n",
    "matRes[7,4]=(100-err)/100\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic=round(dispImp(daTestFM[,\"sex\"],as.factor(yHatFMtreeDP)),3)\n",
    "matRes[7,1:3]=ic\n",
    "ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forests with positive discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:30:22.136477Z",
     "start_time": "2020-03-22T10:28:19.792Z"
    }
   },
   "outputs": [],
   "source": [
    "# model prediction by changing the threshold for women\n",
    "yHatFrfDP=predict(RF.F,newdata=daTestF,type=\"prob\")[,2]>0.3\n",
    "yHatMrfDP=predict(RF.M,newdata=daTestM,type=\"prob\")[,2]>0.5\n",
    "# compilation of predictions\n",
    "yHatFMrfDP=c(yHatFrfDP,yHatMrfDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:30:22.150808Z",
     "start_time": "2020-03-22T10:28:19.799Z"
    }
   },
   "outputs": [],
   "source": [
    "table(yHatFMrfDP,daTestFM$income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:30:22.169554Z",
     "start_time": "2020-03-22T10:28:19.804Z"
    }
   },
   "outputs": [],
   "source": [
    "err=tauxErr(table(yHatFMrfDP,daTestFM$income))\n",
    "matRes[8,4]=(100-err)/100\n",
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What happens to the prediction error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:30:22.193069Z",
     "start_time": "2020-03-22T10:28:19.808Z"
    }
   },
   "outputs": [],
   "source": [
    "ic=round(dispImp(daTestFM[,\"sex\"],as.factor(yHatFMrfDP)),3)\n",
    "matRes[8,1:3]=ic\n",
    "ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** What happens to the bias?\n",
    "### Graphical summary of results\n",
    "The previous results: prediction accuracies and confidence intervals are collected and displayed on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matRes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: uncomment the installation command below when running in the cloud or if this library is simply not installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"Publish\")\n",
    "library(Publish)\n",
    "options(repr.plot.width=10, repr.plot.height=5)\n",
    "plotConfidence(x=matRes[,c(\"DI\",\"Lower\",\"Upper\")],\n",
    "               labels=data.frame(\"Model\"=rownames(matRes),\"Accuracy\"=matRes[,\"Accuracy\"]),\n",
    "               points.pch=15,points.cex=3,points.col=rainbow(6),\n",
    "               values=FALSE,xlim=c(0.1,1),lwd=4,cex=1.5,\n",
    "               xlab=\"Disparate Impact\",xlab.cex=1,xratio=0.3,y.title.offset=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Compare the different bias taking into account the intersection of the confidence intervals. Which algorithms discriminate significantly? Is it efficient to remove the sensitive variable from the model? What about *testing*? How does positive discrimination or post-processing affect the decisions of a binary tree or random forests? Is it efficient? What is the least bad compromise between accuracy, interpretability and bias?\n",
    "\n",
    "**Warning**, mitigating the society bias for more \"fairness\" also impacts the other biases, an impact that is important to consider in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other indicators of bias / discrimination\n",
    "### Bias on conditional prediction errors or accuracies\n",
    "The disparate impact is a first source of bias or discrimination among others. A second source, often mentioned, concerns the prediction errors or accuracies according to the terms of the sensitive variable; this is the \"overall error equality\" or, equivalently, the \"overall accuracy equality\".\n",
    "\n",
    "#### Linear logistic regression\n",
    "*Overall error equality*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:39:10.705393Z",
     "start_time": "2020-03-22T10:39:10.440Z"
    }
   },
   "outputs": [],
   "source": [
    "table(pred.log>0.5,daTest$income,daTest$sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:39:24.570558Z",
     "start_time": "2020-03-22T10:39:24.540Z"
    }
   },
   "outputs": [],
   "source": [
    "apply(table(pred.log>0.5,daTest$income,daTest$sex),3,tauxErr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Q** Which gender appears to be disadvantaged by this criterion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:39:41.729416Z",
     "start_time": "2020-03-22T10:39:41.705Z"
    }
   },
   "outputs": [],
   "source": [
    "source('../Functions/overErrEqual.R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:42:22.775866Z",
     "start_time": "2020-03-22T10:42:22.735Z"
    }
   },
   "outputs": [],
   "source": [
    "round(overErrEqual(daTest$sex,daTest$income,as.factor(pred.log>0.5)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Same question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(yHatTree,daTest$income,daTest$sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply(table(yHatTree,daTest$income,daTest$sex),3,tauxErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(overErrEqual(daTest$sex,daTest$income,yHatTree),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:43:52.534126Z",
     "start_time": "2020-03-22T10:43:52.497Z"
    }
   },
   "outputs": [],
   "source": [
    "apply(table(yHatrf,daTest$income,daTest$sex),3,tauxErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:44:10.443838Z",
     "start_time": "2020-03-22T10:44:10.411Z"
    }
   },
   "outputs": [],
   "source": [
    "round(overErrEqual(daTest$sex,daTest$income,yHatrf),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Which gender appears to be disadvantaged by this criterion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary tree with positive discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tauxErr(table(yHatFtreeDP,daTestF$income)); tauxErr(table(yHatMtreeDP,daTestM$income))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(overErrEqual(daTestFM[,\"sex\"],daTestFM$income,as.factor(yHatFMtreeDP)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Random forest* with  positive discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:46:22.473592Z",
     "start_time": "2020-03-22T10:46:22.441Z"
    }
   },
   "outputs": [],
   "source": [
    "tauxErr(table(yHatFrfDP,daTestF$income)); tauxErr(table(yHatMrfDP,daTestM$income))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:48:01.710243Z",
     "start_time": "2020-03-22T10:48:01.678Z"
    }
   },
   "outputs": [],
   "source": [
    "round(overErrEqual(daTestFM[,\"sex\"],daTestFM$income,as.factor(yHatFMrfDP)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Is the evolution of this criterion logical given the correction adopted on the decision?\n",
    "\n",
    "**Q** Is this correction socially acceptable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Asymmetry of the confusion matrix: *equalitzed odds* \n",
    "Another source of discrimination is considered. It has been highlighted by the site [Propublica](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) concerning the COMPAS recidivism score of the company *equivant* used in some American courts of justice in a form of \"predictive justice\". The bias concerns an inversion of the asymmetry of the confusion matrix according to the sensitive variable. A large number of criteria have been proposed to evaluate this asymmetry and of which [Verma and Rubin (2018](http://fairware.cs.umass.edu/papers/Verma.pdf)) offer a review. Their definitions are based on the different frequencies from the contingency table and calculated by the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:53:16.080696Z",
     "start_time": "2020-03-22T10:53:16.062Z"
    }
   },
   "outputs": [],
   "source": [
    "contRatio <- function(T){ \n",
    "    # Ratios calculés à partir de la matrice de confusion\n",
    "    TP=T[2,2] # true positive\n",
    "    FP=T[2,1] # false positive\n",
    "    FN=T[1,2] # false negative\n",
    "    TN=T[1,1]  # true negative\n",
    "    PPV=TP/(TP+FP) # P(Y=1|g(x)=1) positive predictive value\n",
    "    FDR=FP/(TP+FP) # P(Y=0|g(x)=1) false discovery rate \n",
    "    FOR=FN/(TN+FN) # P(Y=1|g(x)=0) false omission rate\n",
    "    NPV=TN/(TN+FN) # P(Y=0|g(x)=0) negative predictive value\n",
    "    TPR=TP/(TP+FN) # P(g(x)=1|Y=1) true positive rate\n",
    "    FPR=FP/(FP+TN) # P(g(x)=1|Y=0) false positive rate\n",
    "    FNR=FN/(TP+FN) # P(g(x)=0|Y=1) false negative rate\n",
    "    TNR=TN/(FP+TN) # P(g(x)=0|Y=0) true negative rate\n",
    "    return(list(\"PPV\"=PPV,\"FDR\"=FDR,\"FOR\"=FOR,\"NPV\"=NPV,\"TPR\"=TPR,\"FPR\"=FPR,\"FNR\"=FNR,\"TNR\"=TNR))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:53:40.090667Z",
     "start_time": "2020-03-22T10:53:40.052Z"
    }
   },
   "outputs": [],
   "source": [
    "contRatio(table(pred.log>0.5,daTest$income))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of equity criteria that can be defined from the previous frequencies conditionally on the sensitive variable. The combinatorial possibilities are important but can be reduced by noting that *PPV*=1-*FDR*, *FOR*=1-*NPV*, *FPR*=1-*TNR*, *FNR*=1-*TPR*... According to the authors, there is equity of treatment if:\n",
    "- *Predictive parity*: the two groups have the same *PPV*s and consequently the same *FDR*s;\n",
    "- *False positive error rate balance* or *predictive equality*: same *FPR*s and consequently the same *TNR*s;\n",
    "- False negative error rate balance* or *equal opportunity*: same *FNR*s and consequently the same *TPR*s;\n",
    "- Conditional procedure accuracy equality* or *disparate mistreatment* or *equalized odds* combines the two above: same *TPR*s **AND** same *FPR*s;\n",
    "- Overall accuracy equality*: same *TPR* **AND** same *TNR*;\n",
    "- Conditional use accuracy equality*: same *PPV*s **AND** same *NPV*s;\n",
    "- *Teatment equality*: the ratios *FN/FP* are the same for both groups.\n",
    "\n",
    "Many other criteria have been proposed (cf. Verma and Rubin. 2018), they are not developed here. Conditional *TPR* and *TNR* calculations are preferred below, but this is only one choice among others. Friedler et al. (2019) show that these are highly correlated justifying that it is reasonable to restrict ourselves in the first \"reading\" to comparisons of *TPR* and *FPR* only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear logistic regression\n",
    "The confusion matrix is constructed for each gender to compare the different loyalty indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:57:32.837077Z",
     "start_time": "2020-03-22T10:57:32.790Z"
    }
   },
   "outputs": [],
   "source": [
    "fairness=data.frame(\"Female\"=as.matrix(contRatio(table(pred.log>0.5,daTest$income,daTest$sex)[,,1])),\n",
    "                    \"Male\"=as.matrix(contRatio(table(pred.log>0.5,daTest$income,daTest$sex)[,,2])))\n",
    "fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be tedious to construct all the comparisons, especially since many of these indicators are redundant. Only the ***Equalized Odds*** are estimated by confidence intervals using the function `oddsEqual` which admits 4 parameters:\n",
    "- S: protected group variable\n",
    "- Y: target variable\n",
    "- P: prediction $\\hat{Y}$.\n",
    "- alpha=0.05, default value.\n",
    "\n",
    "It provides the confidence interval estimate of the ratios of the conditional *FPR* and *TPR* and thus allows to test the equality or not of the scores according to the sensitive variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T11:00:18.329450Z",
     "start_time": "2020-03-22T11:00:18.308Z"
    }
   },
   "outputs": [],
   "source": [
    "source('../Functions/oddsEqual.R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T11:00:21.283985Z",
     "start_time": "2020-03-22T11:00:21.198Z"
    }
   },
   "outputs": [],
   "source": [
    "round(oddsEqual(daTest$sex,daTest$income,as.factor(pred.log>0.5)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Which genre seems to be favored this time in terms of this criterion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary tree\n",
    "Display of confusion matrices by gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(yHatTree,daTest$income,daTest$sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of the different criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairnessTree=data.frame(\"Female\"=as.matrix(contRatio(table(yHatTree,daTest$income,daTest$sex)[,,1])),\n",
    "                    \"Male\"=as.matrix(contRatio(table(yHatTree,daTest$income,daTest$sex)[,,2])))\n",
    "fairnessTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare, for example, the false positive and false negative rates by gender or the estimates of the reports below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(oddsEqual(daTest$sex,daTest$income,yHatTree),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Same question with a binary tree. What if it were a credit score assessment, what about the risks incurred by the bank by gender and thus the consequent breach of fairness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Random forest* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T11:04:18.581394Z",
     "start_time": "2020-03-22T11:04:18.543Z"
    }
   },
   "outputs": [],
   "source": [
    "fairnessRF=data.frame(\"Female\"=as.matrix(contRatio(table(yHatrf,daTest$income,daTest$sex)[,,1])),\n",
    "                    \"Male\"=as.matrix(contRatio(table(yHatrf,daTest$income,daTest$sex)[,,2])))\n",
    "fairnessRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T11:04:34.202729Z",
     "start_time": "2020-03-22T11:04:34.177Z"
    }
   },
   "outputs": [],
   "source": [
    "round(oddsEqual(daTest$sex,daTest$income,yHatrf),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Same question with a random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary tree with positive discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairnessRFDP=data.frame(\"Female\"=as.matrix(contRatio(table(yHatFtreeDP,daTestF$income))),\n",
    "                    \"Male\"=as.matrix(contRatio(table(yHatMtreeDP,daTestM$income))))\n",
    "fairnessRFDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(oddsEqual(daTestFM[,\"sex\"],daTestFM$income,as.factor(yHatFMtreeDP)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Random forest* with positive discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T11:05:53.395096Z",
     "start_time": "2020-03-22T11:05:53.353Z"
    }
   },
   "outputs": [],
   "source": [
    "fairnessRFDP=data.frame(\"Female\"=as.matrix(contRatio(table(yHatFrfDP,daTestF$income))),\n",
    "                    \"Male\"=as.matrix(contRatio(table(yHatMrfDP,daTestM$income))))\n",
    "fairnessRFDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T11:07:46.482765Z",
     "start_time": "2020-03-22T11:07:46.456Z"
    }
   },
   "outputs": [],
   "source": [
    "round(oddsEqual(daTestFM[,\"sex\"],daTestFM$income,as.factor(yHatFMrfDP)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Does the correction go in the expected direction? \n",
    "\n",
    "**Q** In conclusion, is the post-processing of the threshold, for this example, in the right direction for all the bias criteria?\n",
    "\n",
    "**Q** Comment on the \"recommendations\" of [Goglin (2021)](https://theconversation.com/discrimination-et-ia-comment-limiter-les-risques-en-matiere-de-credit-bancaire-167008)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Conclude on \n",
    "- the choice between a linear model, a tree model, or an aggregation of trees for the quality of the prediction *vs.* the interpretability.\n",
    "- the intervention of the sensitive variable in a model and thus on the effect of a prohibition to take into account a sensitive variable such as the ethnic origin,\n",
    "- the effectiveness of testing, \n",
    "- considering the three types of bias considered, which one would highlight a breach of equity according to gender with regard to the risks incurred by a bank?\n",
    "- the impacts of the rudimentary post-processing implemented on the accuracy, the other biases.\n",
    "\n",
    "Finally, which algorithm to choose and how to justify it from an economic point of view for a bank but also from the point of view of the social image of fairness of the procedure.\n",
    "\n",
    "**Remarks**.\n",
    "- It is probably not necessary to estimate two models according to gender. Post-processing of the decision thresholds alone should suffice.\n",
    "- In the USA, the calculation of the *adverse* or *disparate impact* is taken into account in the hiring process by obligation of the labor code by maintaining \"ethnic statistics\". In France, only testing operations are deployed.\n",
    "- In the USA, the use of a non-linear algorithm without control is risky because a bias that is too important ($DI<0.8$) without explanation, and therefore possible justification, is condemnable. This is why some American `hiring tech' companies offer bias mitigations to save lawsuits (Raghavan et al. 2019).\n",
    "- A `data scientist` currently has a lot of latitude to do whatever he wants, without control: from unfair, condemnable behavior to positive discrimination to introduce more equity in society!\n",
    "- We can hope that, after the implementation of the RGPD, the adoption of the *AI Act* will impact these practices.\n",
    "- A big job in sight for a *data scientist* in charge of a processing that will have to keep a complete and detailed documentation of all these procedures, from data collection to the monitoring of an artificial intelligence system in operation. \n",
    "\n",
    "**It is highly recommended to anticipate this upcoming regulation in order to justify the choices made, i.e. the least bad compromise involving data confidentiality, prediction accuracy, model interpretability and bias or discrimination risks.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Barocas S., Selbst A. (2016). [Big Data's Disparate Impact](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2477899), *California Law Review*, 671.\n",
    "\n",
    "Besse P. (2020). [Détecter, évaluer les risques des impacts discriminatoires des algorithmes d'IA](https://hal.archives-ouvertes.fr/hal-02616963), Contribution au séminaire Défenseur des Droits et CNIL, 28 mai 2020, article soumis.\n",
    "\n",
    "Besse P. del Barrio E. Gordaliza P. Loubes J.-M., Risser L. (2021). [A survey of bias in Machine Learning through the prism of Statistical Parity for the Adult Data Set](https://doi.org/10.1080/00031305.2021.1952897), The American Statistician , DOI: 10.1080/00031305.2021.1952897 [Open access version](https://arxiv.org/pdf/2003.14263.pdf).\n",
    "\n",
    "Efron B. (1987). [Better Bootstrap Confidence Intervals](https://www.jstor.org/stable/2289144?seq=1), *Journal of the American Statistical Association*, Vol. 82, No. 397 (Mar., 1987), pp. 171-185. \n",
    "\n",
    "Friedler S., Scheidegger C., Venkatasubramanian S., Choudhary S., Hamilton E., Roth D. (2019). [A comparative study of fairness-enhancing interventions in machine learning](https://dl.acm.org/doi/10.1145/3287560.3287589), *Proceedings of the Conference on Fairness, Accountability, and Transparency*.\n",
    "\n",
    "Morris S., Lobsenz R. (2000), [Signifiance Tests and Confidence Intervals for the Adverse Impact Ratio](https://doi.org/10.1111/j.1744-6570.2000.tb00195.x) *Personnel Psychology*, 53: 89-111.\n",
    "\n",
    "Riach, P., Rich J. (2002). [Field Experiments of Discrimination In The Market Place]( https://doi.org/10.1111/1468-0297.00080), *The Economic Journal*, Vol. 112, 480-518.\n",
    "\n",
    "Raghavan M., Barocas S., Kleinberg J., Levy K. (2019) [Mitigating bias in Algorithmic Hiring : Evaluating Claims and Practices](https://arxiv.org/abs/1906.09208), arXiv:1906.09208.\n",
    "\n",
    "Verma S., Rubin J. (2018). [Fairness Definitions Explained](http://fairware.cs.umass.edu/papers/Verma.pdf),  *ACM/IEEE International Workshop on Software Fairness*.\n",
    "\n",
    "Zliobaitė I. (2015). [A survey on measuring indirect discrimination in machine learning](https://arxiv.org/pdf/1511.00148.pdf), arXiv preprint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "231.05px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
